{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7ea7e65",
   "metadata": {},
   "source": [
    "### Build a Question Answering application over a Graph Database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d0c0ef",
   "metadata": {},
   "source": [
    "- Initialize the variables u downloaded while creating a free instance from Neo4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a72915c",
   "metadata": {},
   "outputs": [],
   "source": [
    "NEO4J_URI = \"neo4j+s://a6208d63.databases.neo4j.io\"\n",
    "NEO4J_USERNAME = \"neo4j\"\n",
    "NEO4J_PASSWORD = \"rnl7AXFxrALS17r_57UEZ-VKjzuNlsMkyVlPwZyd4Z0\"\n",
    "## U can also put these in the environment varaible if u want and probably read from those environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50d27455",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "## Setting up the environment variables\n",
    "os.environ[\"NEO4J_URI\"] = NEO4J_URI\n",
    "os.environ[\"NEO4J_USERNAME\"] = NEO4J_USERNAME\n",
    "os.environ[\"NEO4J_PASSWORD\"] = NEO4J_PASSWORD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60ea214b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.graphs.neo4j_graph.Neo4jGraph at 0x2484d152cf0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.graphs import Neo4jGraph\n",
    "## Neo4jGraph actually helps u to connect to ur db with the help of the information which u have i.e. NEO4J_URI, NEO4J_USERNAME, NEO4J_PASSWORD\n",
    "graph = Neo4jGraph(url=NEO4J_URI, username=NEO4J_USERNAME, password=NEO4J_PASSWORD)\n",
    "## This way also we will be able to initialize our graph, which will be basically connected to ur entire database\n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7cecec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dataset Movie\n",
    "URL = \"https://raw.githubusercontent.com/tomasonjo/blog-datasets/main/movies/movies_small.csv\"\n",
    "## Above is the RAW Data URL\n",
    "movie_query = \"\"\"\n",
    "LOAD CSV WITH HEADERS FROM\n",
    "'https://raw.githubusercontent.com/tomasonjo/blog-datasets/main/movies/movies_small.csv' as row\n",
    "\n",
    "MERGE(m:Movie{id:row.movieId})\n",
    "SET m.released = date(row.released),\n",
    "    m.title = row.title,\n",
    "    m.imdbRating = toFloat(row.imdbRating)\n",
    "FOREACH (director in split(row.director, '|') |\n",
    "    MERGE (p:Person {name:trim(director)})\n",
    "    MERGE (p)-[:DIRECTED]->(m))\n",
    "FOREACH (actor in split(row.actors, '|') |\n",
    "    MERGE (p:Person {name:trim(actor)})\n",
    "    MERGE (p)-[:ACTED_IN]->(m))\n",
    "FOREACH (genre in split(row.genres, '|') |\n",
    "    MERGE (g:Genre {name:trim(genre)})\n",
    "    MERGE (m)-[:IN_GENRE]->(g))    \n",
    "\"\"\"\n",
    "## We will be putting all the directors in the person node itself\n",
    "## Above we have used SET keyword to assign property to the variables\n",
    "## Above using for each loop we have created multiple relationships: person to movie, actor to movie, movie to genre\n",
    "## This is the query to probably load this entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e633aa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nLOAD CSV WITH HEADERS FROM\\n'https://raw.githubusercontent.com/tomasonjo/blog-datasets/main/movies/movies_small.csv' as row\\n\\nMERGE(m:Movie{id:row.movieId})\\nSET m.released = date(row.released),\\n    m.title = row.title,\\n    m.imdbRating = toFloat(row.imdbRating)\\nFOREACH (director in split(row.director, '|') |\\n    MERGE (p:Person {name:trim(director)})\\n    MERGE (p)-[:DIRECTED]->(m))\\nFOREACH (actor in split(row.actors, '|') |\\n    MERGE (p:Person {name:trim(actor)})\\n    MERGE (p)-[:ACTED_IN]->(m))\\nFOREACH (genre in split(row.genres, '|') |\\n    MERGE (g:Genre {name:trim(genre)})\\n    MERGE (m)-[:IN_GENRE]->(g))    \\n\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f1a10b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.query(movie_query)  ## This is how we execute the query we have specified above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5522bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node properties:\n",
      "CEO {POB: STRING, name: STRING, YOB: INTEGER}\n",
      "Company {name: STRING}\n",
      "Entrepreneur {POB: STRING, name: STRING, YOB: INTEGER}\n",
      "Country {name: STRING}\n",
      "Person {name: STRING, born: INTEGER}\n",
      "Movie {title: STRING, released: INTEGER, id: STRING, imdbRating: FLOAT}\n",
      "User {name: STRING, city: STRING, userId: INTEGER, age: INTEGER}\n",
      "Post {postId: INTEGER, content: STRING, timestamp: DATE_TIME}\n",
      "Genre {name: STRING}\n",
      "Relationship properties:\n",
      "\n",
      "The relationships:\n",
      "(:Entrepreneur)-[:LIVES_IN]->(:Country)\n",
      "(:Person)-[:ACTED_IN]->(:Movie)\n",
      "(:Person)-[:DIRECTED]->(:Movie)\n",
      "(:Movie)-[:IN_GENRE]->(:Genre)\n",
      "(:User)-[:POSTED]->(:Post)\n",
      "(:User)-[:FRIEND]->(:User)\n",
      "(:User)-[:LIKES]->(:User)\n"
     ]
    }
   ],
   "source": [
    "graph.refresh_schema() ## Refreshing the graph schema\n",
    "print(graph.schema)  ## It will show all the Node properties and all the Relationship properties"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7484a22",
   "metadata": {},
   "source": [
    "- Now since u have used the credentials u downloaded for that particular instance in neo4j auradb, u will be able to view it(the graph, nodes, relationships and data) in the Neo4jAuraDB when u try to refresh it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496848c5",
   "metadata": {},
   "source": [
    "- To insert this entire data we just used graph.query() function --> And this executed the entire query itself inside the graph database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1c8e4b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5119b9d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x000002486C21B8C0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x000002486C2133B0>, model_name='llama-3.1-8b-instant', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "llm = ChatGroq(groq_api_key=groq_api_key, model_name=\"llama-3.1-8b-instant\")\n",
    "llm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b6ef63",
   "metadata": {},
   "source": [
    "- Our plan was whenever user writes the query it should probably go to the LLM model this LLM model should create my Cypher Query, and then further by using this cypher query we should be able to query from my graph database and get the output and along with the output i should be able to get back the response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b2ae343e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GraphCypherQAChain(verbose=True, graph=<langchain_community.graphs.neo4j_graph.Neo4jGraph object at 0x000002484D152CF0>, cypher_generation_chain=LLMChain(verbose=False, prompt=PromptTemplate(input_variables=['question', 'schema'], input_types={}, partial_variables={}, template='Task:Generate Cypher statement to query a graph database.\\nInstructions:\\nUse only the provided relationship types and properties in the schema.\\nDo not use any other relationship types or properties that are not provided.\\nSchema:\\n{schema}\\nNote: Do not include any explanations or apologies in your responses.\\nDo not respond to any questions that might ask anything else than for you to construct a Cypher statement.\\nDo not include any text except the generated Cypher statement.\\n\\nThe question is:\\n{question}'), llm=ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x000002486C21B8C0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x000002486C2133B0>, model_name='llama-3.1-8b-instant', model_kwargs={}, groq_api_key=SecretStr('**********')), output_parser=StrOutputParser(), llm_kwargs={}), qa_chain=LLMChain(verbose=False, prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=\"You are an assistant that helps to form nice and human understandable answers.\\nThe information part contains the provided information that you must use to construct an answer.\\nThe provided information is authoritative, you must never doubt it or try to use your internal knowledge to correct it.\\nMake the answer sound as a response to the question. Do not mention that you based the result on the given information.\\nHere is an example:\\n\\nQuestion: Which managers own Neo4j stocks?\\nContext:[manager:CTL LLC, manager:JANE STREET GROUP LLC]\\nHelpful Answer: CTL LLC, JANE STREET GROUP LLC owns Neo4j stocks.\\n\\nFollow this example when generating answers.\\nIf the provided information is empty, say that you don't know the answer.\\nInformation:\\n{context}\\n\\nQuestion: {question}\\nHelpful Answer:\"), llm=ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x000002486C21B8C0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x000002486C2133B0>, model_name='llama-3.1-8b-instant', model_kwargs={}, groq_api_key=SecretStr('**********')), output_parser=StrOutputParser(), llm_kwargs={}), graph_schema='Node properties are the following:\\nCEO {POB: STRING, name: STRING, YOB: INTEGER},Company {name: STRING},Entrepreneur {POB: STRING, name: STRING, YOB: INTEGER},Country {name: STRING},Person {name: STRING, born: INTEGER},Movie {title: STRING, released: INTEGER, id: STRING, imdbRating: FLOAT},User {name: STRING, city: STRING, userId: INTEGER, age: INTEGER},Post {postId: INTEGER, content: STRING, timestamp: DATE_TIME},Genre {name: STRING}\\nRelationship properties are the following:\\n\\nThe relationships are the following:\\n(:Entrepreneur)-[:LIVES_IN]->(:Country),(:Person)-[:ACTED_IN]->(:Movie),(:Person)-[:DIRECTED]->(:Movie),(:Movie)-[:IN_GENRE]->(:Genre),(:User)-[:POSTED]->(:Post),(:User)-[:FRIEND]->(:User),(:User)-[:LIKES]->(:User)', allow_dangerous_requests=True)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import GraphCypherQAChain\n",
    "chain = GraphCypherQAChain.from_llm(graph=graph, llm=llm, allow_dangerous_requests=True, cypher_validation=True, verbose=True)\n",
    "## Bcoz of verbose = True i will be able to see that how the conversation is happening.\n",
    "chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b319d249",
   "metadata": {},
   "source": [
    "- Prompt template over here by default, in this GraphCypherQAChain i do not have to seperately specify my prompt template, bcoz if u go forward there is a prompt template and it is internally using this llm chain. As per this prompt template i need to pass question and schema.\n",
    "- With GraphCypherQAChain it has a default prompt generated along with this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "24509484",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new GraphCypherQAChain chain...\u001b[0m\n",
      "Generated Cypher:\n",
      "\u001b[32;1m\u001b[1;3mMATCH (p:Person)-[:DIRECTED]->(m:Movie {title: \"Casino\"})-[:IN_GENRE]->(g:Genre) RETURN p.name AS director\u001b[0m\n",
      "Full Context:\n",
      "\u001b[32;1m\u001b[1;3m[{'director': 'Martin Scorsese'}, {'director': 'Martin Scorsese'}]\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'query': 'Who was the director of the movie Casino',\n",
       " 'result': 'Martin Scorsese was the director of the movie Casino.'}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chain.invoke({\"query\":\"Who was the director of the movie Casino\"})\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d669581",
   "metadata": {},
   "source": [
    "- Query: MATCH (m:Movie {title:\"Casino\"})<-[:DIRECTED]-(p:Person) RETURN p.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eecc5d7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new GraphCypherQAChain chain...\u001b[0m\n",
      "Generated Cypher:\n",
      "\u001b[32;1m\u001b[1;3mMATCH (m:Movie {title: \"Casino\"})<-[:ACTED_IN]-(p:Person) RETURN p.name\u001b[0m\n",
      "Full Context:\n",
      "\u001b[32;1m\u001b[1;3m[{'p.name': 'Robert De Niro'}, {'p.name': 'Joe Pesci'}, {'p.name': 'Sharon Stone'}, {'p.name': 'James Woods'}]\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'query': 'Who were the actors of the movie Casino',\n",
       " 'result': 'Robert De Niro, Joe Pesci, Sharon Stone, James Woods were actors of the movie Casino.'}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chain.invoke({\"query\":\"Who were the actors of the movie Casino\"})\n",
    "response\n",
    "## Note: Along with the output it is being able to generate the full context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d35f3be0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new GraphCypherQAChain chain...\u001b[0m\n",
      "Generated Cypher:\n",
      "\u001b[32;1m\u001b[1;3mMATCH (p:Person)-[:DIRECTED|ACTED_IN]->(m:Movie) RETURN COUNT(DISTINCT p) AS artists\u001b[0m\n",
      "Full Context:\n",
      "\u001b[32;1m\u001b[1;3m[{'artists': 1240}]\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'query': 'How many artists are there?', 'result': 'There are 1240 artists.'}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chain.invoke({\"query\":\"How many artists are there?\"})\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a104620f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new GraphCypherQAChain chain...\u001b[0m\n",
      "Generated Cypher:\n",
      "\u001b[32;1m\u001b[1;3mMATCH (p:Person)-[:ACTED_IN]->(m:Movie) WHERE p.name = 'Tom Hanks' RETURN COUNT(m)\u001b[0m\n",
      "Full Context:\n",
      "\u001b[32;1m\u001b[1;3m[{'COUNT(m)': 3}]\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'query': 'How many movies has Tom Hanks acted in?',\n",
       " 'result': \"I don't know the answer.\"}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chain.invoke({\"query\":\"How many movies has Tom Hanks acted in?\"})\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f2298b",
   "metadata": {},
   "source": [
    "## Prompting Statergies GraphDB With LLM\n",
    "- Earlier with the help of LLM's we were creating our entire Cypher Queries and based on that we were executing it and retrieving the results from the Graph Database.\n",
    "- There may be scenarios where the LLM may not perform well w.r.t different different complex kind of queries so it is better that we try to improve this graph database query generation mechanism.\n",
    "- Now here what we will do is that we will go with some proper prompting statergies which will try to improve the Graph Database Query Generation.\n",
    "- We will largely focus on methods for getting the relevant database specific information in ur prompt."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
